---
title: "CRK cont SR - Gapfilling"
author: "Moeka"
date: "2024-03-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lubridate)
library(mice)
library(cowplot)
library(dplyr)
library(ggplot2)
```

```{r extract the period}

# just viz
cont_qaqc %>% 
  filter(Datetime_CST > "2023-04-22" & Datetime_CST < "2023-08-25") %>%
  filter(Label == "shallow") %>%
  ggplot() + geom_point(aes(Datetime_CST, Flux))

```

```{r}
# aggregate half hourly to hourly
biomet_23_hr <- 
  biomet_23 %>%
  mutate(Datetime_hr_CST = floor_date(TIMESTAMP_START, unit = "hour")) %>%
  group_by(Datetime_hr_CST) %>%
  summarise(across(CO2_1_1_1:NEE_1_2_1, ~ mean(.x, na.rm = TRUE))) 


```


```{r combine dfs}
# Start from 2023-04-30 20:58 
# End at 2023-08-24 23:14


SR_biomet_23 <- 
 cont_qaqc %>% 
  filter(Datetime_CST > "2023-04-30 20:30:00" & Datetime_CST < "2023-08-24 23:30:00") %>%
  mutate(Datetime_hr_CST = floor_date(Datetime_CST, unit = "hour")) %>% # round it down
  select(c(Datetime_hr_CST, Flux, Label)) %>%
  pivot_wider(names_from = Label,
              values_from = c(Flux)) %>%
  rename(SR = shallow) %>%
  right_join(data.frame(Datetime_hr_CST = seq(as.POSIXct("2023-04-30 20:00:00", tz = "America/Chicago"), 
                                            as_datetime("2023-08-24 23:00:00", tz = "America/Chicago"), 
                                      by = "1 hour")), by = "Datetime_hr_CST") %>%
  left_join(biomet_23_hr, by ="Datetime_hr_CST") %>% 
  arrange(Datetime_hr_CST)

# will think if I want to include the Jan-Feb data
SR_biomet_24 <- 
  SR_feb24[,c(1:4)] %>%
  right_join(data.frame(Datetime_hr_CST = seq(as.POSIXct("2024-02-20 14:00:00", tz = "America/Chicago"), 
                                            as_datetime("2024-03-08 23:00:00", tz = "America/Chicago"), 
                                      by = "1 hour")), by = "Datetime_hr_CST") %>%
  left_join(biomet_24_hr, by ="Datetime_hr_CST") %>% 
  arrange(Datetime_hr_CST)

SR_biomet_may22 <- 
  SR_may22_hr[,c(1:4)] %>%
  right_join(data.frame(Datetime_hr_CST = seq(as.POSIXct("2022-05-22 01:00:00", tz = "America/Chicago"), 
                                            as_datetime("2022-06-09 23:00:00", tz = "America/Chicago"), 
                                      by = "1 hour")), by = "Datetime_hr_CST") %>%
  left_join(biomet_22_hr, by ="Datetime_hr_CST") %>% 
  arrange(Datetime_hr_CST)

```

```{r imputing data - check the data coverage}
pMiss <- function(x){sum(is.na(x))/length(x)*100}

apply(SR_biomet_23,2,pMiss)
apply(SR_biomet_24,2,pMiss)
```

# data covarage 2023
SR - 14.4%
TS_1_1_1 ~ TS_2_3_1 - 0.36%
SWC_1_1_1 - 0.36%
PPFD_IN_1_1_1 - 0.32%

Result produced by FluxGapR: 
Total gaps:       74
- < 1 day:          73
- >= 1 & < 7 days:  1
- >= 7 & < 15 days: 0
- >= 15 days:       0
- Failed gaps:      0


# data covarage 2024 as of March 9
SR - 0.96%
Rh & Ra - 1.20%
Ts_1_1_1 ~ Ts_2_3_1 - 0%
Ta_1_1_1 = 0.71 %
SWC_1_1_1 & 1_2_1 - 0%
PPFD_1_1_1 - 0.72%





# the benefit of Mice package
The advantage of a Multiple Imputation package like mice is, that you have multiple imputed datasets, which can help account for uncertainties that occur by performing the imputation. If you only want 1 imputed dataset you can use Single Imputation packages like missForest, imputeR, VIM which are sometimes a little bit easier to use / understand syntax wise.

ref: https://appsilon.com/imputation-in-r/
https://stackoverflow.com/questions/55146099/multiple-imputation-in-r-mice-how-do-i-test-imputation-runs
```{r imputation 1 - mice multiple methods}

SR_biomet_23_selected <- 
  SR_biomet_23 %>%
  select(c(SR, TS_1_1_1, SWC_1_1_1, PPFD_IN_1_1_1)) 

md.pattern(SR_biomet_23_selected)

mice_imp_SR23 <- 
  data.frame(
    original = SR_biomet_23$SR,
    imputed_pmm = complete(mice(SR_biomet_23_selected, method = "pmm"))$SR,
    imputed_cart = complete(mice(SR_biomet_23_selected, method = "cart"))$SR,
    imputed_lasso = complete(mice(SR_biomet_23_selected, method = "lasso.norm"))$SR,
    imputed_rf = complete(mice(SR_biomet_23_selected, method = "rf"))$SR
  )

h1 <- ggplot(mice_imp_SR23, aes(x = original)) +
  geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
  ggtitle("Original distribution") +
  theme_classic()
h2 <- ggplot(mice_imp_SR23, aes(x = imputed_pmm)) +
  geom_histogram(fill = "#15ad4f", color = "#000000", position = "identity") +
  ggtitle("PMM-imputed distribution") +
  theme_classic()
h3 <- ggplot(mice_imp_SR23, aes(x = imputed_cart)) +
  geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
  ggtitle("CART-imputed distribution") +
  theme_classic()
h4 <- ggplot(mice_imp_SR23, aes(x = imputed_lasso)) +
  geom_histogram(fill = "#ad8415", color = "#000000", position = "identity") +
  ggtitle("Lasso-imputed distribution") +
  theme_classic()
h5 <- ggplot(mice_imp_SR23, aes(x = imputed_rf)) +
  geom_histogram(fill = "#f37735", color = "#000000", position = "identity") +
  ggtitle("Random forest distribution") +
  theme_classic()

plot_grid(h1, h2, h3, h4, h5, ncol = 2)

# CART distribution seems the closest to the original


# use the CART for the other variables
SR_biomet_23_cart <- 
  complete(mice(SR_biomet_23_selected, method = "cart"))

# combine with timestamp
SR_biomet_23_cart_ts <- 
  cbind(SR_biomet_23[,1], SR_biomet_23_cart)

mice_imp_SR23_ts <- 
  cbind(SR_biomet_23[,1], mice_imp_SR23)

ggplot(mice_imp_SR23_ts) +
  geom_point(aes(x = Datetime_hr_CST, y = original, col = "original"), alpha = .8) + 
  geom_point(aes(x = Datetime_hr_CST, y = imputed_pmm, col = "pmm"), alpha = .3) +
  geom_point(aes(x = Datetime_hr_CST, y = imputed_cart, col = "cart"), alpha = .3) +
  geom_point(aes(x = Datetime_hr_CST, y = imputed_rf, col = "rf"), alpha = .3) +
  scale_color_manual("", values = c( "#1543ad", "#ad1538", "#15ad4f", "#f37735")) +
  ylab("SR umol m-2 s-1") + xlab("") + theme_bw() +
  theme(axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15),
          axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15),
          legend.title = element_text(size = 15), legend.text = element_text(size = 15))
  
```
CART or Random Forest seems a good fit. Lasso excluded because the distribution doesn't seem to be similar with the original. PMM excluded because of the noisy spread.

# imputing Ts, SWC, TA 
Those three variables are missing at the same time between 2023-06-10 21:00 ~ 2023-06-11 5:00. Without filling them first, SR cannot be gapfilled 
```{r}
SR_biomet_23_imp <-   
  complete(mice(SR_biomet_23 %>% 
                select(TS_1_1_1, TS_2_1_1, TA_1_1_1, SWC_1_1_1, PPFD_IN_1_1_1), 
                method = "rf")) %>%
  cbind(SR_biomet_23[,c(1,2)]) 

# for 2024
SR_biomet_24_imp <-   
  complete(mice(SR_biomet_24 %>% 
                select(Ts_1_1_1, Ts_2_1_1, Ta_1_1_1, SWC_1_1_1, PPFD_1_1_1), 
                method = "rf")) %>%
  cbind(SR_biomet_24[,c(1:3)]) 

# for 2022 may
SR_biomet_may22_imp <-   
  complete(mice(SR_biomet_may22 %>% 
                select(TS_1_1_1, TS_2_1_1, TA_1_1_1, SWC_1_1_1, PPFD_IN_1_1_1), 
                method = "rf")) %>%
  cbind(SR_biomet_may22[,c(1:3)]) 

```


```{r imputation 2 - Q10 model}



```

MDS = marginal distribution sampling
```{r Gapfill 3 - MDS}
SR_biomet_23_MDS <-
  cont_qaqc %>% 
  filter(Datetime_CST > "2023-04-30 20:30:00" & Datetime_CST < "2023-08-24 23:30:00") %>%
  mutate(Datetime_hr_CST = floor_date(Datetime_CST, unit = "hour")) %>% # round it down
  select(c(Datetime_hr_CST, Flux, Label)) %>%
  pivot_wider(names_from = Label,
              values_from = c(Flux)) %>%
  rename(SR = shallow) %>%
  right_join(data.frame(Datetime_hr_CST = seq(as.POSIXct("2023-04-30 01:00:00", tz = "America/Chicago"), 
                                            as_datetime("2023-08-25 0:00:00", tz = "America/Chicago"), 
                                      by = "1 hour")), by = "Datetime_hr_CST") %>%
  left_join(biomet_23_hr, by ="Datetime_hr_CST") %>% 
  arrange(Datetime_hr_CST) %>%
  mutate(Ts5 = (TS_1_1_1 + TS_2_2_1)/2)

# the timestamp has to start from 1:00:00 and end with 0:00:00
# DTS: Number of daily time steps (24 or 48) 
# ID.s can be any string but has to be inputed
# ref: https://rdrr.io/rforge/REddyProc/man/sEddyProc.new.html
EProc <- sEddyProc$new(
  'CRK', SR_biomet_23_MDS, c('SR',"Ts5"),
  ColPOSIXTime = "Datetime_hr_CST", DTS = 24)  

# Visualize the data coverage
# Year can be any string but has to be inputed
EProc$sPlotFingerprintY('SR', Year = "2023")



# ref: https://rdrr.io/rforge/REddyProc/man/sMDSGapFill.html
EProc$sMDSGapFill(
  Var = 'SR', QFVar = 'none', QFValue = NA_real_, V1 = "Ts5")

grep("SR_.*_f$",names(EProc$sExportResults()), value = TRUE)
grep("SR_.*_fsd$",names(EProc$sExportResults()), value = TRUE)

# Viz after gap filled
EProc$sPlotFingerprintY('SR_f', Year = "2023")

#Saving results 
SR_biomet_23_MDS_res <- cbind(SR_biomet_23_MDS, EProc$sExportResults())



# write.csv(SR_biomet_23_MDS_res, 
#           file = "G:/My Drive/Research/Projects/DC_auto/SR_biomet_23_MDS_Ts5_res.csv", 
#           row.names = FALSE)

```


LLyod and Taylor (1994)
Using FluxGapsR package: chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://presentations.copernicus.org/EGU2020/EGU2020-2174_presentation.pdf

If you have missing data in TS, it will be NA

ref: https://rdrr.io/github/junbinzhao/FluxGapsR/man/Gapfill_nls.html
```{r Gapfill 4  - NLS}

# source code: https://github.com/junbinzhao/FluxGapsR/blob/master/R/Gapf_NLS.R
Gapfill_nls_custom <- function(data,
                        Flux = "Flux",
                        Ts = "Ts",
                        win = 5,
                        interval = 10,
                        R10 = 10,
                        E0 = 400,
                        fail = "ave"
){
    # # define the pipe from the package "magrittr"
    `%>%` <- magrittr::`%>%`
    ### add sequence mark to the gaps -------
    mt <- is.na(data[,Flux])
    ind <- 1 # index for marking the gaps
    mk <- vector()
    for (i in 1:length(mt)) {
        if (mt[i]==FALSE){
            mk[i] <- 0 # non-gaps are marked as 0
        } else {
            if (mt[i]==TRUE){
                mk[i] <- ind # gaps are marked as the value of ind
                if (i != length(mt)){ # to prevent the error when loop reach the end
                    if (mt[i+1]==FALSE) {
                        ind <- ind+1 # when reached the end of a gap, change add 1 to ind
                    }
                }
            }
        }
    }
    print(paste0(max(mk)," gaps are marked")) # display the total number of gaps
    
    ### prepare data for gapfilling -----
    # the sampling window length
    pt_h <- 60/interval # how many data points per hour
    winID <- win/2*pt_h*24 # how many data points for the sampling window at EACH side of the gap
    # create vector to save the predicted gapfilled data
    gap <- rep(NA,nrow(data))
    # extract the data needed for gap-filling
    dft <- data[,c(Flux,Ts)]
    names(dft) <- c("Flux","Ts")
    # a vector for marks of each gap
    mark <- rep(0,nrow(dft))
    # a number to record the number of failed regression
    nf <- 0
    
    ### gap filling by the marked index of each gap ----------
    for (i in 1:max(mk)) {
        indx <- which(mk==i) # index of the gap
        # define the sampling window
        wind_st <- ifelse(min(indx)-winID>=0,min(indx)-winID,1) # use the beginning of time series if not enough sample points are present
        wind_ed <- ifelse(max(indx)+winID>nrow(data),nrow(data),max(indx)+winID) # use the end if not enough
        
        # fit the Lloyd-Taylor model
        fit1 <- try(minpack.lm::nlsLM(Flux~a*exp(b*(1/(283.15-227.13)-1/(Ts-227.13))),
                                      start = list(a=R10,b=E0),
                                      data = dft[wind_st:wind_ed,],
                                      control=minpack.lm::nls.lm.control(maxiter = 1000)
        ),
        silent = TRUE)
        # fit the basic model
        fit2 <- try(minpack.lm::nlsLM(Flux~a*exp(b*Ts),
                                      start = list(a=1,b=0.1),
                                      data = dft[wind_st:wind_ed,],
                                      control=minpack.lm::nls.lm.control(maxiter = 1000)
        ),
        silent = TRUE)
        
        # choose the model
        if (class(fit1)!="try-error") {
            if (class(fit2)!="try-error"){
                if (sum(summary(fit1)$residuals) > sum(summary(fit2)$residuals)){ # both are not error, choose the one with smaller residuals
                    fit <- fit2
                } else {
                    fit <- fit1
                }
            } else { # if fit2 is error, fit1 is not
                fit <- fit1
            }
        } else { # if fit1 is error
            fit <- fit2
        }
        
        # predict the gaps
        if (class(fit)!="try-error"){ # if the fit converged
            gap[indx] <- predict(fit,newdata=dft[indx,])
            mark[indx] <- 1 # filled gap
            print(paste0("#",i," out of ",max(mk)," gaps: succeed!!")) # for checking progress
        } else {
            if (fail == "ave"){ # use average in the sampling window
                gap[indx] <- mean(dft$Flux[wind_st:wind_ed],na.rm = T)
                mark[indx] <- 2 # failed to filled gap
                nf <- nf+1 # add up the failed times
                print(paste0("#",i," out of ",max(mk)," gaps: Failed...")) # for checking progress
            } else { # or use the designated value
                gap[indx] <- fail
                mark[indx] <- 2 # failed to filled gap
                nf <- nf+1 # add up the failed times
                print(paste0("#",i," out of ",max(mk)," gaps: Failed...")) # for checking progress
            }
        }
    } # end of the loop
    df_new <- data.frame(data,
                         filled = gap,
                         tem = dft[,"Flux"],   # tem WAS NOT GENERATED
                         mark) %>%
        dplyr::mutate(filled = ifelse(mark==0,.[[5]],filled)) # I CHANGED THIS PART
    
    # print a summary of the gapfilling ------------
    stat <- table(mk)[-1] # number of data points in each gap
    # print using "cat" for break into lines
    cat(paste0("","\n",
               "##### Summary #####","\n",
               "","\n",
               "Total gaps:       ",max(mk),"\n",
               "< 1 day:          ",sum(stat<pt_h*24),"\n",
               ">= 1 & < 7 days:  ",sum(stat>=pt_h*24 & stat<pt_h*24*7),"\n",
               ">= 7 & < 15 days: ",sum(stat>=pt_h*24*7 & stat<pt_h*24*15),"\n",
               ">= 15 days:       ",sum(stat>=pt_h*24*15),"\n",
               "Failed gaps:      ",nf
    ))
    # return the output data frame
    return(df_new)
}




# apply the function
SR_biomet_23_NLS <- SR_biomet_23_imp %>% 
  mutate(Ts5 = ifelse(is.na(TS_2_1_1), TS_1_1_1, (TS_1_1_1+TS_2_1_1)/2)) %>%
  select(Datetime_hr_CST,Ts5, SR) %>% 
  Gapfill_nls(Ts = "Ts5", Flux = "SR") %>%
  rename(NLS_filled = filled)


# viz 
ggplot(SR_biomet_23_NLS) + 
  geom_point(aes(Datetime_hr_CST, filled, col = as.character(mark)))

```

If you have missing data in input data, it will be NA
```{r Gapfill 5  - ANN}
# source code: https://rdrr.io/github/junbinzhao/FluxGapsR/src/R/Gapf_ANN.R
Gapfill_ann_custom <- function(data,
                        Flux = "Flux",
                        var1,
                        var2 = NULL,
                        var3 = NULL,
                        win = 5,
                        interval = 10,
                        threshold = 1,
                        hidden = 2,
                        fail = "ave",
                        ...
){
  # # define the pipe from the package "magrittr"
  `%>%` <- magrittr::`%>%`
  ### add sequence mark to the gaps -------
  mt <- is.na(data[,Flux])
  ind <- 1 # index for marking the gaps
  mk <- vector()
  for (i in 1:length(mt)) {
    if (mt[i]==FALSE){
      mk[i] <- 0 # non-gaps are marked as 0
    } else {
      if (mt[i]==TRUE){
        mk[i] <- ind # gaps are marked as the value of ind
        if (i != length(mt)){ # to prevent the error when loop reach the end
          if (mt[i+1]==FALSE) {
            ind <- ind+1 # when reached the end of a gap, change add 1 to ind
          }
        }
      }
    }
  }
  print(paste0(max(mk)," gaps are marked")) # display the total number of gaps

  ### prepare data for gapfilling -----
  # the sampling window length
  pt_h <- 60/interval # how many data points per hour
  winID <- win/2*pt_h*24 # how many data points for the sampling window at EACH side of the gap
  # create vector to save the predicted gapfilled data
  gap <- rep(NA,nrow(data))

  #  based on variable numbers
  if (is.null(var2)){ # if one variable
    # extract the data needed for gap-filling
    dft <- data[,c(Flux,var1)]
    names(dft) <- c("Flux","var1")
    # scale and normalize the input variables
    dft <- dft %>%
      dplyr::mutate(var1=scale(var1))
    formula <- as.formula("Flux~var1")
  } else {
    if (is.null(var3)){ # if two variables
      # extract the data needed for gap-filling
      dft <- data[,c(Flux,var1,var2)]
      names(dft) <- c("Flux","var1","var2")
      # scale and normalize the input variables
      dft <- dft %>%
        dplyr::mutate(var1=scale(var1),
               var2=scale(var2))
      formula <- as.formula("Flux~var1+var2")
    } else { # if three variables
      # extract the data needed for gap-filling
      dft <- data[,c(Flux,var1,var2,var3)]
      names(dft) <- c("Flux","var1","var2","var3")
      # scale and normalize the input variables
      dft <- dft %>%
        dplyr::mutate(var1=scale(var1),
               var2=scale(var2),
               var3=scale(var3))
      formula <- as.formula("Flux~var1+var2+var3")
    }
  }


  # a vector for marks of each gap
  mark <- rep(0,nrow(dft))
  # a number to record the number of failed regression
  nf <- 0

  ### gap filling by the marked index of each gap ----------
  for (i in 1:max(mk)) {
    indx <- which(mk==i) # index of the gap
    # define the sampling window
    wind_st <- ifelse(min(indx)-winID>=0,min(indx)-winID,1) # use the beginning of time series if not enough sample points are present
    wind_ed <- ifelse(max(indx)+winID>nrow(data),nrow(data),max(indx)+winID) # use the end if not enough
    # extract data to fit the model
    df_ann <- dft[wind_st:wind_ed,] %>%
      na.omit(.) # remove data in the gap

    # ANN model
    nn <- try(neuralnet::neuralnet(formula = formula,
                                   data = df_ann,
                                   # data = dft[sample(c(1:nrow(dft)),size = 2000),], ## sample a fraction of data for test
                                   threshold = threshold, # increase the threshold to improve the chance of converge
                                   stepmax = 1e+07, # increase the max step to improve the chance of converge
                                   hidden = hidden, #
                                   linear.output = T,...), # regression, not classification
                                   silent = TRUE)

    # predict the gaps
    if (class(nn)!="try-error"){ # if the fit converged
      gap[indx] <- predict(nn,newdata=dft[indx,])
      mark[indx] <- 1 # filled gap
      print(paste0("#",i," out of ",max(mk)," gaps: succeed!!")) # for checking progress
    } else {
      if (fail == "ave"){ # use average in the sampling window
        gap[indx] <- mean(dft$Flux[wind_st:wind_ed],na.rm = T)
        mark[indx] <- 2 # failed to filled gap
        nf <- nf+1 # add up the failed times
        print(paste0("#",i," out of ",max(mk)," gaps: Failed...")) # for checking progress
      } else { # or use the designated value
        gap[indx] <- fail
        mark[indx] <- 2 # failed to filled gap
        nf <- nf+1 # add up the failed times
        print(paste0("#",i," out of ",max(mk)," gaps: Failed...")) # for checking progress
      }
    }
  } # end of the loop
  df_new <- data.frame(data,
                       filled = gap,
                       tem = dft[,"Flux"],
                       mark) %>%
    dplyr::mutate(filled = ifelse(mark==0,.[[7]],filled)) 

  # print a summary of the gapfilling ------------
  stat <- table(mk)[-1] # number of data points in each gap
  # print using "cat" for break into lines
  cat(paste0("","\n",
             "##### Summary #####","\n",
             "","\n",
             "Total gaps:       ",max(mk),"\n",
             "< 1 day:          ",sum(stat<pt_h*24),"\n",
             ">= 1 & < 7 days:  ",sum(stat>=pt_h*24 & stat<pt_h*24*7),"\n",
             ">= 7 & < 15 days: ",sum(stat>=pt_h*24*7 & stat<pt_h*24*15),"\n",
             ">= 15 days:       ",sum(stat>=pt_h*24*15),"\n",
             "Failed gaps:      ",nf
  ))
  # return the output data frame
  return(df_new)
}



# apply the function
SR_biomet_23_ANN <- SR_biomet_23_imp %>% 
  mutate(Ts5 = ifelse(is.na(TS_2_1_1), TS_1_1_1, (TS_1_1_1+TS_2_1_1)/2)) %>%
  select(Datetime_hr_CST, SR, Ts5, SWC_1_1_1, TA_1_1_1) %>% 
  # watch out when changein the number of variables - you gotta modify the source function
  Gapfill_ann(Flux = "SR", var1 = "Ts5", var2 = "SWC_1_1_1", var3 = "TA_1_1_1") %>%
  rename(ANN_filled = filled)


# 2024
SR_biomet_24_ANN_SR <- SR_biomet_24_imp %>% 
  mutate(Ts5 = (Ts_1_1_1+Ts_2_1_1)/2) %>%
  select(Datetime_hr_CST, SR, Ts5, SWC_1_1_1, Ta_1_1_1) %>% 
  # watch out when changein the number of variables - you gotta modify the source function
  Gapfill_ann(Flux = "SR", var1 = "Ts5", var2 = "SWC_1_1_1", var3 = "Ta_1_1_1") %>%
  rename(SR_filled = filled)

SR_biomet_24_ANN_Rh <- SR_biomet_24_imp %>% 
  mutate(Ts5 = (Ts_1_1_1+Ts_2_1_1)/2) %>%
  select(Datetime_hr_CST, Rh, Ts5, SWC_1_1_1, Ta_1_1_1) %>% 
  # watch out when changein the number of variables - you gotta modify the source function
  Gapfill_ann(Flux = "Rh", var1 = "Ts5", var2 = "SWC_1_1_1", var3 = "Ta_1_1_1") %>%
  rename(Rh_filled = filled)


SR_biomet_24_ANN <- 
  cbind(SR_biomet_24_ANN_SR[,c(1,3:6)], SR_biomet_24_ANN_Rh[,6]) %>%
  rename(Rh_filled = 'SR_biomet_24_ANN_Rh[, 6]') %>%
  mutate(Ra_imp = SR_filled - Rh_filled)


# 2022 may - make a function
SR_biomet_22_ANN_SR <- SR_biomet_may22_imp %>% 
  mutate(Ts5 = (TS_1_1_1+TS_2_1_1)/2) %>%
  select(Datetime_hr_CST, SR, Ts5, SWC_1_1_1, TA_1_1_1) %>% 
  # watch out when changein the number of variables - you gotta modify the source function
  Gapfill_ann(Flux = "SR", var1 = "Ts5", var2 = "SWC_1_1_1", var3 = "TA_1_1_1") %>%
  rename(SR_filled = filled)

SR_biomet_22_ANN_Rh <- SR_biomet_may22_imp %>% 
  mutate(Ts5 = (TS_1_1_1+TS_2_1_1)/2) %>%
  select(Datetime_hr_CST, Rh, Ts5, SWC_1_1_1, TA_1_1_1) %>% 
  # watch out when changein the number of variables - you gotta modify the source function
  Gapfill_ann(Flux = "Rh", var1 = "Ts5", var2 = "SWC_1_1_1", var3 = "TA_1_1_1") %>%
  rename(Rh_filled = filled)


SR_biomet_24_ANN <- 
  cbind(SR_biomet_24_ANN_SR[,c(1,3:6)], SR_biomet_24_ANN_Rh[,6]) %>%
  rename(Rh_filled = 'SR_biomet_24_ANN_Rh[, 6]') %>%
  mutate(Ra_imp = SR_filled - Rh_filled)


SR_biomet_may22_ANN <- 
  cbind(SR_biomet_22_ANN_SR[,c(1,3:6)], SR_biomet_22_ANN_Rh[,6]) %>%
  rename(Rh_filled = 'SR_biomet_22_ANN_Rh[, 6]') %>%
  mutate(Ra_imp = SR_filled - Rh_filled)



# viz 
ggplot(SR_biomet_23_ANN) + 
  geom_point(aes(Datetime_hr_CST, ANN_filled, col = as.character(mark)))
```
Wanted to try out the SSA method in FlaxgapR but the primary package is outdated and did not work.


Combine all the imputation methods 
```{r}
SR23_gapfilled <- 
  left_join(mice_imp_SR23_ts, SR_biomet_23_ANN %>% select(c(Datetime_hr_CST, ANN_filled)), by = "Datetime_hr_CST") %>%
  left_join(SR_biomet_23_NLS %>% select(c(Datetime_hr_CST, NLS_filled)), by = "Datetime_hr_CST") %>% 
  right_join(SR_biomet_23_MDS_res%>% select(c(Datetime_hr_CST, SR_f, SR_fqc)), by = "Datetime_hr_CST") %>% 
  rename(MDS_filled = SR_f, MDS_fqc = SR_fqc)
  
```

Comparing the results
```{r }
ggplot(SR23_gapfilled) +
  geom_point(aes(Datetime_hr_CST, original, color = 'Orig'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, imputed_cart, color = 'CART'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, imputed_rf, color = 'RF'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, ANN_filled, color = 'ANN'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, NLS_filled, color = 'NLS'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, MDS_filled, color = 'MDS'), alpha = .1) +
  labs(x="", y = "Soil CO2 Efflux(umolCO2 m-2 s-1)", color = "Flux") +
  theme_bw() + 
  theme(axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15),
          axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15),
          legend.title = element_text(size = 15), legend.text = element_text(size = 15))

# closer look at the biggest gap
ggplot(SR23_gapfilled %>% filter(Datetime_hr_CST > "2023-05-10" & Datetime_hr_CST < "2023-06-01")) +
  geom_point(aes(Datetime_hr_CST, original, color = 'Orig'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, imputed_cart, color = 'CART'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, imputed_rf, color = 'RF'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, ANN_filled, color = 'ANN'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, NLS_filled, color = 'NLS'), alpha = .3) +
  geom_point(aes(Datetime_hr_CST, MDS_filled, color = 'MDS'), alpha = .3) +
  labs(x = "",y = "Soil CO2 Efflux(umolCO2 m-2 s-1)", color = "Flux") +
  theme_bw() + 
  theme(axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15),
          axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15),
          legend.title = element_text(size = 15), legend.text = element_text(size = 15))



# 
# write.csv(SR23_gapfilled,
#           file = "G:/My Drive/Research/Projects/DC_auto/SR_biomet_23_res.csv",
#           row.names = FALSE)

```


Use ANN for SR and RF for Ts, SWC, and PAR





